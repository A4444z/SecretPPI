import os
import argparse
import yaml
import torch
import torch.nn.functional as F
from tqdm import tqdm
from torch_geometric.loader import DataLoader as PyGDataLoader

from src.models.glue_cmae import GlueVAE
from src.data.dataset import GlueVAEDataset

@torch.no_grad()
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='config_cmae.yaml')
    parser.add_argument('--checkpoint', type=str, required=True)
    parser.add_argument('--device', type=str, default='cuda:0')
    parser.add_argument('--chunk_size', type=int, default=1024, help='æ¯æ¬¡å¤„ç†çš„æŸ¥è¯¢æ ·æœ¬æ•°')
    parser.add_argument('--save_features', action='store_true', help='æ˜¯å¦ä¿å­˜æå–çš„ç‰¹å¾ä»¥å¤‡åç”¨')
    args = parser.parse_args()

    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')

    # ç‰¹å¾ä¿å­˜è·¯å¾„
    feat_path = f"{args.checkpoint}_features.pt"

    if os.path.exists(feat_path):
        print(f"â™»ï¸ å‘ç°å·²å­˜åœ¨çš„ç‰¹å¾ç¼“å­˜: {feat_path}, æ­£åœ¨ç›´æ¥åŠ è½½...")
        data = torch.load(feat_path)
        Z1_global = data['Z1']
        Z2_global = data['Z2']
    else:
        print("ğŸš€ åŠ è½½éªŒè¯é›†å¹¶å¼€å§‹æå–ç‰¹å¾...")
        val_dataset = GlueVAEDataset(
            root=config['data']['root_dir'],
            lmdb_path=config['data']['lmdb_path'],
            split='val',
            exclude_pdb_json=config['data'].get('exclude_pdb_json'),
            random_rotation=False,
            max_samples=config['data'].get('max_samples', None),
            cutoff_radius=config['training'].get('recon_cutoff', 15.0)
        )
        val_loader = PyGDataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

        model = GlueVAE(
            hidden_dim=config['model']['hidden_dim'],
            num_encoder_layers=config['model']['num_encoder_layers'],
            num_decoder_layers=config['model']['num_decoder_layers'],
            edge_dim=config['model']['edge_dim'],
            vocab_size=config['model']['vocab_size'],
            use_gradient_checkpointing=False
        ).to(device)

        checkpoint = torch.load(args.checkpoint, map_location=device)
        state_dict = checkpoint['model_state_dict']
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        model.eval()

        all_z1, all_z2 = [], []
        for batch in tqdm(val_loader, desc="Feature Extraction"):
            batch = batch.to(device)
            # è°ƒç”¨ forwardï¼Œç”±äº model.eval()ï¼Œä¼šè¿›å…¥ç¡®å®šæ€§åˆ†æ”¯
            graph_z1, graph_z2, _, _ = model(
                z=batch.x, vector_features=batch.vector_features,
                edge_index=batch.edge_index, edge_attr=batch.edge_attr,
                pos=batch.pos, residue_index=batch.residue_index,
                is_ligand=batch.is_ligand, mask_interface=batch.mask_interface,
                batch_idx=batch.batch
            )
            all_z1.append(graph_z1.cpu())
            all_z2.append(graph_z2.cpu())

        Z1_global = torch.cat(all_z1, dim=0)
        Z2_global = torch.cat(all_z2, dim=0)

        if args.save_features:
            torch.save({'Z1': Z1_global, 'Z2': Z2_global}, feat_path)
            print(f"ğŸ’¾ ç‰¹å¾å·²ä¿å­˜è‡³: {feat_path}")

    N_total = Z1_global.size(0)
    print(f"\nğŸ“Š æ­£åœ¨è¿›è¡Œå…¨å±€æ£€ç´¢æµ‹è¯• (åº“å¤§å°: {N_total})...")
    
    # ================= ğŸš¨ åˆ†å—è®¡ç®—æ ¸å¿ƒé€»è¾‘ (é¿å… 1.4TB OOM) =================
    top1_correct = 0
    top5_correct = 0
    total_pos_sim = 0.0
    
    # å°†å€™é€‰åº“æ”¾åœ¨ GPU ä¸Š (çº¦ 300MBï¼Œéå¸¸å®‰å…¨)
    Z2_global = Z2_global.to(device) 
    
    for i in tqdm(range(0, N_total, args.chunk_size), desc="Chunked Matching"):
        end = min(i + args.chunk_size, N_total)
        z1_chunk = Z1_global[i:end].to(device) # [Chunk, D]
        
        # è®¡ç®—è¯¥å—çš„ç›¸ä¼¼åº¦çŸ©é˜µ [Chunk, N_total]
        sim_chunk = torch.matmul(z1_chunk, Z2_global.T) 
        
        # 1. æ­£æ ·æœ¬ç›¸ä¼¼åº¦ (å¯¹è§’çº¿å…ƒç´ )
        total_pos_sim += torch.diagonal(sim_chunk[:, i:end]).sum().item()
        
        # 2. Top-1 å‘½ä¸­æ•°
        preds_top1 = sim_chunk.argmax(dim=-1)
        targets = torch.arange(i, end, device=device)
        top1_correct += (preds_top1 == targets).sum().item()
        
        # 3. Top-5 å‘½ä¸­æ•°
        _, preds_top5 = sim_chunk.topk(5, dim=-1)
        top5_correct += (preds_top5 == targets.unsqueeze(1)).any(dim=-1).sum().item()

    avg_top1 = top1_correct / N_total
    avg_top5 = top5_correct / N_total
    avg_pos_sim = total_pos_sim / N_total

    print("\n" + "="*40)
    print("ğŸ† æ·±åº¦æ£€ç´¢æŠ¥å‘Š (Memory Efficient)")
    print("="*40)
    print(f"æ€»æ ·æœ¬æ•°: {N_total}")
    print(f"Top-1 å‡†ç¡®ç‡: {avg_top1 * 100:.2f}%")
    print(f"Top-5 å‡†ç¡®ç‡: {avg_top5 * 100:.2f}%")
    print(f"æ­£æ ·æœ¬å¹³å‡ç›¸ä¼¼åº¦: {avg_pos_sim:.4f}")
    print("="*40)

if __name__ == "__main__":
    main()