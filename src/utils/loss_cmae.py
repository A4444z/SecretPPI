"""
æŸå¤±å‡½æ•°æ¨¡å— (CMAE æ¶æ„)ã€‚
å®ç° InfoNCE æŸå¤±å’ŒåŸºäºæ©ç çš„ D-RMSD é‡æ„æŸå¤±ï¼Œç”¨äºå­¦ä¹ è›‹ç™½è´¨äº’ä½œæµå½¢ã€‚
"""

import torch
import torch.nn as nn
from torch_geometric.utils import to_dense_batch

# ================= 1. æ ¸å¿ƒé‡æ„æŸå¤±ï¼šMasked D-RMSD =================

class MaskedDRMSDLoss(nn.Module):
    """
    æ©ç  D-RMSD æŸå¤±å‡½æ•° (å¸¦å±€éƒ¨æˆªæ–­)ã€‚
    ğŸš¨ å…³é”®ç‰¹æ€§ï¼šåªè®¡ç®—è¢«æ©ç ï¼ˆè¢«ç ´åï¼‰çš„åŸå­ä¸å…¶å®ƒæœ‰æ•ˆåŸå­ä¹‹é—´çš„ç›¸å¯¹è·ç¦»è¯¯å·®ã€‚
    """
    
    def __init__(self, reduction='mean', cutoff=15.0):
        super().__init__()
        self.reduction = reduction
        self.cutoff = cutoff 
        
    def forward(
        self,
        pos_pred,
        pos_true,
        mask_v1,     # ğŸ‘ˆ å¿…é¡»ä¼ å…¥ forward ä¸­ç”Ÿæˆçš„ mask_v1
        batch_idx=None
    ):
        if batch_idx is None:
            batch_idx = torch.zeros(pos_pred.size(0), dtype=torch.long, device=pos_pred.device)
        
        # è½¬ä¸ºå¯†é›†çŸ©é˜µ [B, N_max, 3]
        pos_pred_dense, batch_mask = to_dense_batch(pos_pred, batch_idx)
        pos_true_dense, _ = to_dense_batch(pos_true, batch_idx)
        mask_v1_dense, _ = to_dense_batch(mask_v1.float(), batch_idx) # [B, N_max]
        
        # è®¡ç®—æˆå¯¹è·ç¦» [B, N_max, N_max]
        D_pred = torch.cdist(pos_pred_dense, pos_pred_dense, p=2.0)
        D_true = torch.cdist(pos_true_dense, pos_true_dense, p=2.0)
        
        mse = (D_pred - D_true) ** 2
        
        # 1. æœ‰æ•ˆèŠ‚ç‚¹æ©ç  (å»é™¤ padding)
        valid_2d = batch_mask.unsqueeze(1) * batch_mask.unsqueeze(2)
        
        # 2. å±€éƒ¨è·ç¦»æˆªæ–­æ©ç  (åªå…³æ³¨ cutoff å†…çš„ç‰©ç†äº’ä½œ)
        cutoff_mask = (D_true < self.cutoff).float()
        
        # å»é™¤å¯¹è§’çº¿ (è‡ªå·±åˆ°è‡ªå·±)
        eye_mask = 1.0 - torch.eye(D_true.size(1), device=D_true.device).unsqueeze(0)
        
        # 3. ğŸš¨ æ ¸å¿ƒæ©ç é€»è¾‘ï¼šè‡³å°‘æœ‰ä¸€ä¸ªåŸå­æ˜¯è¢«ç‚¸æ‰çš„ (mask_v1)
        # å¦‚æœ i å’Œ j éƒ½æ²¡è¢«ç‚¸æ‰ï¼Œé‚£æ¨¡å‹å°±æ˜¯ä½œå¼Šç…§æŠ„ï¼Œæˆ‘ä»¬ä¸å¥–åŠ±å®ƒã€‚
        # åªæœ‰å½“ i æˆ– j æ˜¯è¢«ç ´åçš„åŸå­æ—¶ï¼Œé‡æ„å…¶è·ç¦»æ‰æœ‰æ„ä¹‰ã€‚
        mask_i = mask_v1_dense.unsqueeze(2) # [B, N_max, 1]
        mask_j = mask_v1_dense.unsqueeze(1) # [B, 1, N_max]
        
        # mask_i + mask_j > 0 è¡¨ç¤ºï¼šè¿™å¯¹åŸå­ä¸­è‡³å°‘æœ‰ä¸€ä¸ªå±äºè¢«ç ´åçš„åŒºåŸŸ
        masked_region_mask = (mask_i + mask_j > 0.5).float()
        
        # ç»„åˆæœ€ç»ˆæ©ç 
        final_mask = valid_2d * cutoff_mask * eye_mask * masked_region_mask
        
        mse = mse * final_mask
        
        if self.reduction == 'mean':
            # åˆ†æ¯ä½¿ç”¨å®é™…å‚ä¸è®¡ç®—çš„æœ‰æ•ˆ Masked Pair æ•°é‡
            return mse.sum() / (final_mask.sum() + 1e-8)
        return mse.sum()

# ================= 2. æ ¸å¿ƒå¯¹æ¯”æŸå¤±ï¼šInfoNCE =================

class InfoNCELoss(nn.Module):
    """
    InfoNCE / NT-Xent å¯¹æ¯”æŸå¤±ã€‚
    å°†åŒä¸€ä¸ªå¤åˆç‰©çš„ä¸¤ä¸ªè§†å›¾æ‹‰è¿‘ï¼Œå°† Batch å†…å…¶ä»–å¤åˆç‰©æ¨å¼€ã€‚
    """
    def __init__(self, temperature=0.1):
        super().__init__()
        self.temperature = temperature

    def forward(self, z1, z2):
        """
        å‚æ•°:
            z1: [B, D] L2 å½’ä¸€åŒ–åçš„è§†å›¾1è¡¨å¾
            z2: [B, D] L2 å½’ä¸€åŒ–åçš„è§†å›¾2è¡¨å¾
        """
        B = z1.shape[0]
        # æ‹¼æ¥æˆ [2B, D] çš„å¤§å¼ é‡
        z = torch.cat([z1, z2], dim=0)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ [2B, 2B] (å› ä¸º z å·²ç»å½’ä¸€åŒ–ï¼Œç‚¹ä¹˜å°±æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦)
        sim = torch.matmul(z, z.T) / self.temperature

        # æ„å»ºæ­£æ ·æœ¬ç´¢å¼•
        # å¯¹äº z1[i]ï¼Œæ­£æ ·æœ¬æ˜¯ z2[i]ï¼Œç´¢å¼•ä¸º i + B
        # å¯¹äº z2[i]ï¼Œæ­£æ ·æœ¬æ˜¯ z1[i]ï¼Œç´¢å¼•ä¸º i (å› ä¸º i æœ¬èº«æ˜¯ i+B å‡å» B)
        positives = torch.cat([torch.arange(B, 2*B), torch.arange(0, B)], dim=0).to(z1.device)

        # æå–æ­£æ ·æœ¬çš„ç›¸ä¼¼åº¦ [2B, 1]
        pos_sim = sim[torch.arange(2*B), positives].unsqueeze(1)

        # æ„å»º Logits æ©ç ï¼Œå»é™¤è‡ªèº«ç›¸ä¼¼åº¦ (å¯¹è§’çº¿)
        logits_mask = ~torch.eye(2*B, dtype=torch.bool, device=z.device)
        
        # å–å‡ºéè‡ªèº«çš„ç›¸ä¼¼åº¦ [2B, 2B - 1] ä½œä¸ºåˆ†æ¯å€™é€‰
        logits = sim[logits_mask].view(2*B, -1)

        # InfoNCE = -log( exp(pos) / sum(exp(all_except_self)) )
        # ä¸ºäº†æ•°å€¼ç¨³å®šï¼Œé€šå¸¸ç”¨ log_softmax æˆ–æ‰‹åŠ¨å¹³ç§»
        exp_logits = torch.exp(logits)
        denom = exp_logits.sum(dim=1, keepdim=True)
        loss = - torch.log(torch.exp(pos_sim) / denom)
        
        return loss.mean()

# ================= 3. ç»„åˆå¼•æ“ï¼šCMAE Loss =================

class CMAELoss(nn.Module):
    """
    Contrastive Masked Autoencoder è”åˆæŸå¤±ã€‚
    åŒ…å«ï¼šæ‹‰ä¼¸æµå½¢çš„ InfoNCE + ç‰©ç†ä¿çœŸçš„ Masked_DRMSD
    """
    def __init__(
        self,
        temperature=0.1,
        lambda_contrast=1.0,
        lambda_recon=0.5,
        cutoff=15.0
    ):
        super().__init__()
        self.lambda_contrast = lambda_contrast
        self.lambda_recon = lambda_recon
        
        self.info_nce_loss = InfoNCELoss(temperature=temperature)
        self.drmsd_loss = MaskedDRMSDLoss(reduction='mean', cutoff=cutoff)
        
    def forward(
        self,
        z1,
        z2,
        pos_pred_v1,
        pos_true,
        mask_v1,
        batch_idx
    ):
        # 1. è®¡ç®— InfoNCE å¯¹æ¯”æŸå¤±
        contrast_loss = self.info_nce_loss(z1, z2)
        
        # 2. è®¡ç®—ä»…åœ¨ Masked åŒºåŸŸçš„é‡æ„æŸå¤±
        recon_loss = self.drmsd_loss(pos_pred_v1, pos_true, mask_v1, batch_idx)
        
        # 3. ç»„åˆæ€»æŸå¤±
        total_loss = self.lambda_contrast * contrast_loss + self.lambda_recon * recon_loss
        
        return total_loss, contrast_loss, recon_loss

# ================= é™„å½•ï¼šæ¸…ç†å†—ä½™ =================
# æ—§çš„ KLLoss, BetaScheduler, VAELoss, CoordinateDecoder å·²è¢«å½»åº•åˆ é™¤ã€‚