import os
import argparse
import json
import torch
import torch.nn.functional as F
from tqdm import tqdm
from torch_geometric.loader import DataLoader as PyGDataLoader
import yaml


from src.models.glue_cmae import GlueVAE
from src.data.dataset import GlueVAEDataset

def load_config(config_path):
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    parser = argparse.ArgumentParser(description='CMAE Test Set Evaluation (Old Model)')
    parser.add_argument('--config', type=str, default='config_cmae.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--checkpoint', type=str, required=True, help='è®­ç»ƒå¥½çš„ .pt æƒé‡è·¯å¾„')
    parser.add_argument('--test_lmdb', type=str, required=True, help='æµ‹è¯•é›† LMDB è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='eval_results', help='è¾“å‡ºç»“æœç›®å½•')
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Using device: {device}")

    config = load_config(args.config)

    # 1. æ„å»ºæµ‹è¯•æ•°æ®é›† (å…³é—­éšæœºæ—‹è½¬)
    print("åŠ è½½æµ‹è¯•é›†...")
    test_dataset = GlueVAEDataset(
        root=config['data']['root_dir'],
        lmdb_path=args.test_lmdb,
        split='test',
        random_rotation=False # è¯„ä¼°æ—¶å¿…é¡»å…³é—­éšæœºæ—‹è½¬
    )
    
    test_loader = PyGDataLoader(
        test_dataset,
        batch_size=config['data']['batch_size'],
        shuffle=False, # æµ‹è¯•é›†ä¸éœ€è¦æ‰“ä¹±ï¼Œæ–¹ä¾¿å¯¹åº” PDB ID
        num_workers=4,
        drop_last=False
    )

    # 2. åˆå§‹åŒ–æ—§ç‰ˆæ¨¡å‹å¹¶åŠ è½½æƒé‡
    print("åŠ è½½æ—§ç‰ˆ CMAE (scatter_mean) æ¨¡å‹...")
    # ğŸš¨ æ³¨æ„ï¼šå»æ‰äº† mask_noiseï¼Œå› ä¸ºæ—§ç‰ˆ __init__ ä¸æ¥å—è¿™ä¸ªå‚æ•°
    model = GlueVAE(
        hidden_dim=config['model']['hidden_dim'],
        num_encoder_layers=config['model']['num_encoder_layers'],
        num_decoder_layers=config['model']['num_decoder_layers'],
        edge_dim=config['model']['edge_dim'],
        vocab_size=config['model']['vocab_size'],
        use_gradient_checkpointing=False
    ).to(device)

    # å…¼å®¹ DDP æƒé‡åŠ è½½ (å‰¥ç¦» 'module.' å‰ç¼€)
    checkpoint = torch.load(args.checkpoint, map_location=device)
    state_dict = checkpoint['model_state_dict']
    clean_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(clean_state_dict)
    model.eval()

    # 3. æ”¶é›†æ•°æ®çš„å®¹å™¨
    all_z1 = []
    all_z2 = []
    all_pdb_ids = []
    
    total_rmsd = 0.0
    valid_rmsd_batches = 0

    # 4. å‰å‘ä¼ æ’­æ”¶é›†ç‰¹å¾
    print("ğŸ§  å¼€å§‹ç‰¹å¾æå–ä¸ç‰©ç†é‡æ„è¯„ä¼°...")
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Evaluating"):
            batch = batch.to(device)
            
            
            graph_z1, graph_z2, pos_pred_v1, mask_v1, batch_entropy, attn_guidance_loss = model(
                z=batch.x,
                vector_features=batch.vector_features,
                edge_index=batch.edge_index,
                edge_attr=batch.edge_attr,
                pos=batch.pos,
                residue_index=batch.residue_index,
                is_ligand=batch.is_ligand,
                mask_interface=batch.mask_interface,
                batch_idx=batch.batch
            )
                        
            # æ”¶é›†å¯¹æ¯”å‘é‡ (ç¡®ä¿åœ¨ CPU ä¸Šä¿å­˜)
            all_z1.append(graph_z1.cpu())
            all_z2.append(graph_z2.cpu())
            if hasattr(batch, 'pdb_id'):
                all_pdb_ids.extend(batch.pdb_id)
                
            # è®¡ç®—ç‰©ç†åæ ‡ RMSD (åªè®¡ç®—è¢« Mask çš„åŒºåŸŸ)
            if mask_v1.sum() > 0:
                pos_true = batch.pos[mask_v1]
                pos_pred = pos_pred_v1[mask_v1]
                # è®¡ç®—å‡æ–¹æ ¹è¯¯å·® (Ã…)
                rmsd = torch.sqrt(F.mse_loss(pos_pred, pos_true)).item()
                total_rmsd += rmsd
                valid_rmsd_batches += 1

    # æ‹¼æ¥å…¨é›†ç‰¹å¾
    all_z1 = torch.cat(all_z1, dim=0) # [N, proj_dim]
    all_z2 = torch.cat(all_z2, dim=0) # [N, proj_dim]
    
    avg_mask_rmsd = total_rmsd / max(1, valid_rmsd_batches)

    # 5. è®¡ç®—å…¨å±€æ£€ç´¢æŒ‡æ ‡ (Global Retrieval)
    print("ğŸ” è®¡ç®—å…¨å±€å¯¹æ¯”å­¦ä¹ æ£€ç´¢æŒ‡æ ‡...")
    N = all_z1.size(0)
    
    # è®¡ç®—å…¨é›†ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ [N, N]
    sim_matrix = torch.matmul(all_z1, all_z2.T)
    
    # æ­£ç¡®ç­”æ¡ˆæ˜¯å¯¹è§’çº¿ä¸Šçš„å…ƒç´ 
    targets = torch.arange(N)
    
    # å¯¹ç›¸ä¼¼åº¦çŸ©é˜µæŒ‰è¡Œé™åºæ’åˆ—ï¼Œè·å–æ’åç´¢å¼•
    sorted_indices = sim_matrix.argsort(dim=-1, descending=True)
    
    # æ‰¾åˆ° Target åœ¨æ’åºåçš„é˜Ÿä¼ä¸­æ’ç¬¬å‡  (æ’åä» 1 å¼€å§‹)
    ranks = (sorted_indices == targets.unsqueeze(1)).nonzero(as_tuple=True)[1] + 1
    
    # è®¡ç®—é‡åŒ–æŒ‡æ ‡
    mrr = (1.0 / ranks.float()).mean().item()
    top1 = (ranks == 1).float().mean().item()
    top5 = (ranks <= 5).float().mean().item()
    top10 = (ranks <= 10).float().mean().item()
    
    # è®¡ç®—æ­£è´Ÿæ ·æœ¬å¹³å‡ç›¸ä¼¼åº¦
    pos_sim = torch.diagonal(sim_matrix).mean().item()
    mask_neg = ~torch.eye(N, dtype=torch.bool)
    neg_sim = sim_matrix[mask_neg].mean().item()

    # 6. ç”ŸæˆæŠ¥å‘Šå¹¶ä¿å­˜
    report = {
        "dataset_size": N,
        "retrieval_metrics": {
            "MRR (å¹³å‡å€’æ•°æ’å)": round(mrr, 4),
            "Top-1 Acc": round(top1, 4),
            "Top-5 Acc": round(top5, 4),
            "Top-10 Acc": round(top10, 4)
        },
        "manifold_metrics": {
            "Positive_Similarity (æ­£æ ·æœ¬)": round(pos_sim, 4),
            "Negative_Similarity (è´Ÿæ ·æœ¬)": round(neg_sim, 4),
            "Margin (é—´è·)": round(pos_sim - neg_sim, 4)
        },
        "physics_metrics": {
            "Masked_Region_Coordinate_RMSD (Ã…)": round(avg_mask_rmsd, 4)
        }
    }

    # æ‰“å°åˆ°ç»ˆç«¯
    print("\n" + "="*40)
    print("ğŸ“Š CMAE æµ‹è¯•é›†è¯„ä¼°æŠ¥å‘Š (Old Model)")
    print("="*40)
    print(json.dumps(report, indent=4, ensure_ascii=False))
    print("="*40)

    # å¯¼å‡º JSON æŠ¥å‘Š
    json_path = os.path.join(args.output_dir, 'cmae_eval_attn_report.json')
    with open(json_path, 'w') as f:
        json.dump(report, f, indent=4, ensure_ascii=False)

    # å¯¼å‡ºç‰¹å¾æ•°æ®
    feature_path = os.path.join(args.output_dir, 'cmae_test_attn_features.pt')
    torch.save({
        'z1_receptor': all_z1,
        'z2_ligand': all_z2,
        'pdb_ids': all_pdb_ids,
        'sim_matrix': sim_matrix
    }, feature_path)
    
    print(f"âœ… è¯„ä¼°å®Œæˆï¼\næŠ¥å‘Šå·²ä¿å­˜è‡³: {json_path}\nç‰¹å¾å·²ä¿å­˜è‡³: {feature_path}")

if __name__ == "__main__":
    main()