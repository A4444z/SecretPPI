import os
import sys

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ï¼ˆå³é¡¹ç›®æ ¹ç›®å½•ï¼‰ï¼Œå¹¶åŠ å…¥ç³»ç»Ÿè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)


import re
import glob
import yaml
import torch
from torch_geometric.data import Batch

# ä»åº•å±‚æ–‡ä»¶å¯¼å…¥
from inference_screening import VirtualScreener, parse_pdb_to_pyg, save_patch_with_attention_to_pdb

def main():
    print("==================================================")
    print("ğŸš€ CMAE åŒç›²é«˜é€šé‡è™šæ‹Ÿç­›é€‰ (All-to-All Scanning)")
    print("==================================================")

    # ================= 1. å®éªŒå‚æ•°é…ç½® =================
    CONFIG_PATH = '/home/fit/liulei/WORK/SecretPPI/config_cmae.yaml'
    MODEL_WEIGHTS = "/home/fit/liulei/WORK/SecretPPI/checkpoints/checkpoint_1159610_epoch_39.pt"  
    
    # é¶ç‚¹ A é…ç½® (æ— éœ€æŒ‡å®šæ®‹åŸºäº†)
    TARGET_PDB_PATH = "/home/fit/liulei/WORK/SecretPPI/database/AFDB_human/AF-Q92560-F1-model_v6.pdb"
    NUM_TARGET_PATCHES = 20 # è›‹ç™½ A è¡¨é¢é‡‡æ ·çš„æ–‘å—æ•°
    
    # å€™é€‰åº“ B é…ç½®
    CANDIDATE_DIR = "/home/fit/liulei/WORK/SecretPPI/database/AFDB_human"  
    NUM_SAMPLED_PATCHES = 20 # æ¯ä¸ªè›‹ç™½ B è¡¨é¢é‡‡æ ·çš„æ–‘å—æ•°

    # ğŸš¨ æ–°å¢ï¼šè°ƒè¯•/éªŒè¯é˜¶æ®µæ§åˆ¶è›‹ç™½ B æ•°ç›®çš„å¼€å…³
    # è®¾ä¸ºå…·ä½“çš„æ•°å­— (å¦‚ 50) åˆ™åªæµ‹ 50 ä¸ªï¼›è®¾ä¸º None åˆ™ç«åŠ›å…¨å¼€ï¼Œæ‰«æ•´ä¸ªåº“ï¼
    MAX_CANDIDATES = None
    
    OUTPUT_DIR = "/home/fit/liulei/WORK/SecretPPI/screening_results"
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    # ===================================================

    with open(CONFIG_PATH, 'r') as f:
        config = yaml.safe_load(f)
    screener = VirtualScreener(model_path=MODEL_WEIGHTS, config=config)
    
    # 3. ğŸ¯ ã€æ”¹åŠ¨ç‚¹ã€‘å¯¹ç›®æ ‡è›‹ç™½ A è¿›è¡Œè‡ªåŠ¨å…¨æ™¯é‡‡æ ·
    print(f"\nğŸ”‘ æ­£åœ¨è§£æå¹¶è‡ªåŠ¨é‡‡æ ·ç›®æ ‡è›‹ç™½ A: {TARGET_PDB_PATH}")
    protein_A_full = parse_pdb_to_pyg(TARGET_PDB_PATH)
    
    # ä½¿ç”¨è‡ªåŠ¨æå–ä»£æ›¿æ‰‹åŠ¨æå–
    target_patches = screener.extract_patches_auto(protein_A_full, num_patches=NUM_TARGET_PATCHES)
    batch_targets = Batch.from_data_list(target_patches)
    z_targets, attn_weights_A = screener.get_latent_representation(batch_targets) # [N_A, 128]
    print(f"âœ… è›‹ç™½ A è¡¨é¢å…±æå–äº† {len(target_patches)} ä¸ªå€™é€‰æ–‘å—ï¼\n")

    # =====================================================================
    # 4. å‡†å¤‡å®æ—¶ CSV è®°å½•å™¨ & éå†å€™é€‰åº“ B
    # =====================================================================
    candidate_files = glob.glob(os.path.join(CANDIDATE_DIR, "*.pdb"))
    candidate_files = [f for f in candidate_files if os.path.basename(f) != os.path.basename(TARGET_PDB_PATH)]
    
    if MAX_CANDIDATES is not None and MAX_CANDIDATES < len(candidate_files):
        import random
        print(f"âš ï¸ [è°ƒè¯•æ¨¡å¼] åŸæœ¬æœ‰ {len(candidate_files)} ä¸ªå€™é€‰è›‹ç™½ã€‚")
        random.seed(42) 
        random.shuffle(candidate_files)
        candidate_files = candidate_files[:MAX_CANDIDATES]
        print(f"âš ï¸ [è°ƒè¯•æ¨¡å¼] å·²å¼€å¯æˆªæ–­ï¼Œæœ¬æ¬¡åªç­›é€‰ {MAX_CANDIDATES} ä¸ªè›‹ç™½ Bï¼")
    else:
        print(f"ğŸ“‚ å‘ç° {len(candidate_files)} ä¸ªå€™é€‰è›‹ç™½ï¼Œç«åŠ›å…¨å¼€...")
    
    # ğŸ¯ æ–°å¢ï¼šåˆ›å»º CSV æ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
    # ğŸ¯ ä¿®æ”¹ï¼šå¢åŠ  UniProt_ID åˆ—
    csv_filename = f"All_Scores_{os.path.basename(TARGET_PDB_PATH).replace('.pdb', '')}.csv"
    csv_filepath = os.path.join(OUTPUT_DIR, csv_filename)
    with open(csv_filepath, 'w', encoding='utf-8') as f:
        f.write("Candidate_PDB,UniProt_ID,Match_Score\n")
    print(f"ğŸ“„ å°†å®æ—¶è®°å½•æ‰€æœ‰æ‰“åˆ†åˆ° CSV è¡¨æ ¼: {csv_filepath}")
    
    print(f"å¼€å§‹çŸ©é˜µäº¤å‰åŒ¹é…...\n")
    
    screening_results = []
    MAX_KEEP = 100 # å†…å­˜ä¸­åªä¿ç•™æ’åå‰ 100 çš„è¯¦æƒ…æ•°æ®ï¼Œé˜²æ­¢çˆ†å†…å­˜

    for idx, cand_path in enumerate(candidate_files):
        pdb_name = os.path.basename(cand_path)
        
        try:
            cand_full = parse_pdb_to_pyg(cand_path)
            candidate_patches = screener.extract_patches_auto(cand_full, num_patches=NUM_SAMPLED_PATCHES)
            
            if not candidate_patches:
                continue
                
            batch_candidates = Batch.from_data_list(candidate_patches)
            z_candidates, attn_weights_B = screener.get_latent_representation(batch_candidates) # [N_B, 128]
            
            # ğŸ¯ è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µå¹¶æå–æœ€å¤§åˆ†
            similarities = torch.matmul(z_candidates, z_targets.T)
            best_score = torch.max(similarities).item()
            flat_idx = torch.argmax(similarities)
            
            best_idx_B = (flat_idx // similarities.shape[1]).item()
            best_idx_A = (flat_idx % similarities.shape[1]).item()
            
            # ğŸ¯ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾å‡†æå– UniProt ID
            # ä» "AF-Q3LI81-F1-model_v6.pdb" ä¸­æå–å‡º "Q3LI81"
            
            match = re.search(r'AF-(.+?)-F\d+', pdb_name)
            uniprot_id = match.group(1) if match else "UNKNOWN"
            
            # ğŸ¯ æé«˜ç²¾åº¦ï¼šä½¿ç”¨ .6f ä¿ç•™ 6 ä½å°æ•°
            with open(csv_filepath, 'a', encoding='utf-8') as f:
                f.write(f"{pdb_name},{uniprot_id},{best_score:.6f}\n")

            # å°†è¯¦ç»†ç»“æœå½•å…¥å†…å­˜æ’è¡Œæ¦œï¼ˆåŠ ä¸Š uniprot_idï¼‰
            screening_results.append({
                'pdb_name': pdb_name,
                'uniprot_id': uniprot_id, # ğŸ‘ˆ æ–°å¢è¿™ä¸€è¡Œ
                'best_score': best_score,
                'best_patch_B': candidate_patches[best_idx_B],
                'best_attn_B': attn_weights_B[batch_candidates.batch == best_idx_B].mean(dim=-1).cpu().numpy(),
                'best_patch_A': target_patches[best_idx_A],
                'best_attn_A': attn_weights_A[batch_targets.batch == best_idx_A].mean(dim=-1).cpu().numpy()
            })
            
            # ğŸ›¡ï¸ å†…å­˜æŠ¤èˆªï¼šæ¯æ‰«ææ»¡ 50 ä¸ªï¼Œæ¸…ç†ä¸€æ¬¡å†…å­˜ä¸­æ’åé åçš„åºå¤§å›¾å¯¹è±¡
            if len(screening_results) > 200:
                screening_results.sort(key=lambda x: x['best_score'], reverse=True)
                screening_results = screening_results[:MAX_KEEP]
                
        except Exception as e:
            # é‡åˆ°è§£æé”™è¯¯ï¼Œä¹Ÿåœ¨ CSV ä¸­è®°å½•ä¸‹æ¥ï¼Œæ–¹ä¾¿äº‹åæ’æŸ¥
            with open(csv_filepath, 'a', encoding='utf-8') as f:
                f.write(f"{pdb_name},ERROR\n")
            print(f"âŒ è§£æ {pdb_name} å¤±è´¥: {e}")

    # 5. æ’è¡Œæ¦œ
    screening_results.sort(key=lambda x: x['best_score'], reverse=True)

    print("\n" + "="*60)
    print("ğŸ† åŒç›²è™šæ‹Ÿç­›é€‰æœ€ç»ˆæ’è¡Œæ¦œ (Top 10)")
    print("="*60)
    for rank, res in enumerate(screening_results[:10]):
        # ğŸ‘ˆ è¿™é‡Œä½¿ç”¨ res['uniprot_id'] æ›¿ä»£å†—é•¿çš„ pdb_nameï¼Œå¹¶æ˜¾ç¤º 6 ä½å°æ•°
        print(f"Rank {rank+1:02d}: {res['uniprot_id']:<15} | æœ€é«˜åŒ¹é…åº¦: {res['best_score']:.6f}")
    print("="*60)
    
    # 6. ã€é«˜é˜¶ã€‘åŒæ—¶å¯¼å‡ºè›‹ç™½ A å’Œè›‹ç™½ B äº’ç›¸çœ‹å¯¹çœ¼çš„ä¸¤ä¸ªå£è¢‹ï¼
    if len(screening_results) > 0:
        print(f"\nğŸ’¾ æ­£åœ¨å¯¼å‡º Top-1 å¥‘åˆé…å¯¹çš„çƒ­åŠ›å›¾åˆ° {OUTPUT_DIR} ...")
        top1 = screening_results[0]
        
        # ğŸ‘ˆ æ–‡ä»¶åä¹Ÿæ¢æˆå¹²å‡€çš„ UniProt ID
        save_patch_with_attention_to_pdb(
            top1['best_patch_A'], 
            top1['best_attn_A'], 
            out_path=os.path.join(OUTPUT_DIR, f"Top1_ProteinA_Pocket_for_{top1['uniprot_id']}.pdb")
        )
        save_patch_with_attention_to_pdb(
            top1['best_patch_B'], 
            top1['best_attn_B'], 
            out_path=os.path.join(OUTPUT_DIR, f"Top1_ProteinB_Pocket_from_{top1['uniprot_id']}.pdb")
        )
        print("âœ… å¯¼å‡ºå®Œæ¯•ï¼æ¨¡å‹ä¸ä»…æ‰¾å‡ºäº†è›‹ç™½ B çš„é¶ç‚¹ï¼Œè¿˜æŒ‡å‡ºäº†å®ƒæ˜¯ç”¨è›‹ç™½ A çš„å“ªä¸ªéƒ¨ä½ç»“åˆçš„ï¼")


if __name__ == "__main__":
    main()